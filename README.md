# Stock Price Prediction API

<div align="center">

![Python](https://img.shields.io/badge/python-3.12+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)
![MLflow](https://img.shields.io/badge/MLflow-2.0+-blue.svg)
![Docker](https://img.shields.io/badge/Docker-ready-brightgreen.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

LSTM-based stock price prediction REST API with MLflow tracking and Docker deployment.

[Quick Start](#quick-start) â€¢
[Features](#features) â€¢
[API Docs](#api-documentation) â€¢
[Docker](#docker-deployment) â€¢
[Development](#development)

</div>

---

## Features

âœ¨ **Production-Ready ML API**
- ğŸ¯ LSTM model for time series prediction
- ğŸ“Š Real-time stock data fetching with `yfinance`
- ğŸ”„ MLflow experiment tracking and model registry
- ğŸ“ˆ Prometheus metrics for monitoring
- ğŸ³ Docker containerization
- ğŸ§ª Comprehensive test coverage

ğŸ—ï¸ **Clean Architecture**
- Domain-driven design
- Dependency injection
- SOLID principles
- Testable components

ğŸš€ **Developer Experience**
- FastAPI with auto-generated docs
- Structured logging with `structlog`
- Pre-commit hooks for code quality
- Type hints throughout
- Hot reload for development

## Quick Start

### With Docker (Recommended)

```bash
# Clone repository
git clone https://github.com/your-repo/mlops-lstm-stock-prediction.git
cd mlops-lstm-stock-prediction

# Start services
docker-compose up -d

# Access services
# API: http://localhost:8000
# API Docs: http://localhost:8000/docs
# MLflow UI: http://localhost:5000
```

### Without Docker

```bash
# Install UV
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install dependencies
make install

# Initialize MLflow
uv run python scripts/init_mlflow.py

# Run API
make run-api
```

## API Documentation

### Endpoints

#### `POST /api/v1/train`
Train a new LSTM model for a stock symbol.

```bash
curl -X POST http://localhost:8000/api/v1/train \
  -H "Content-Type: application/json" \
  -d '{
    "symbol": "AAPL",
    "period": "1y",
    "config": {
      "hidden_size": 50,
      "num_layers": 2,
      "epochs": 100
    }
  }'
```

#### `POST /api/v1/predict`
Generate prediction using existing model.

```bash
curl -X POST http://localhost:8000/api/v1/predict \
  -H "Content-Type: application/json" \
  -d '{
    "symbol": "AAPL",
    "model_version": "latest"
  }'
```

#### `POST /api/v1/predict/train-predict`
Complete pipeline: train and predict in one call.

#### `GET /api/v1/health`
Health check endpoint.

```bash
curl http://localhost:8000/api/v1/health
```

#### `GET /api/v1/models`
List all trained models from MLflow Registry.

#### `GET /api/v1/models/{symbol}/latest`
Get information about the latest model for a symbol.

#### `GET /metrics`
Prometheus metrics endpoint.

### Interactive Documentation

- **Swagger UI:** http://localhost:8000/docs
- **ReDoc:** http://localhost:8000/redoc

## Docker Deployment

### Quick Commands

```bash
# Build image
make docker-build

# Start services
make docker-run

# View logs
make docker-logs

# Stop services
make docker-stop

# Check status
make docker-ps

# Clean up
make docker-clean
```

### Docker Compose

**Production:**
```bash
docker-compose up -d
```

**Development (with hot reload):**
```bash
docker-compose -f docker-compose.dev.yml up -d
```

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Docker Compose Stack                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ API         â”‚     â”‚ MLflow UI   â”‚       â”‚
â”‚  â”‚ Port 8000   â”‚â—„â”€â”€â”€â”€â”¤ Port 5000   â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚         â”‚                   â”‚               â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                  â–¼                          â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚         â”‚ Shared Volume  â”‚                  â”‚
â”‚         â”‚ - mlflow.db    â”‚                  â”‚
â”‚         â”‚ - artifacts    â”‚                  â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Development

### Setup

```bash
# Install dependencies
make install

# Install pre-commit hooks
make pre-commit-install

# Run pre-commit checks
make pre-commit-run
```

### Testing

```bash
# Run all tests
make test

# Run unit tests only
make test-unit

# Run with coverage
make test-coverage

# Run fast tests (excluding slow ones)
make test-fast
```

### Code Quality

```bash
# Format code
make format

# Run linter
make check

# Format + lint
make lint
```

### Project Structure

```
mlops_lstm_stock_prediction/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ domain/              # Domain entities and models
â”‚   â”œâ”€â”€ application/         # Use cases and services
â”‚   â”œâ”€â”€ infrastructure/      # External integrations
â”‚   â”‚   â”œâ”€â”€ data/           # Data loaders
â”‚   â”‚   â”œâ”€â”€ model/          # LSTM model
â”‚   â”‚   â””â”€â”€ mlflow/         # MLflow integration
â”‚   â””â”€â”€ presentation/        # FastAPI endpoints
â”‚       â”œâ”€â”€ api/
â”‚       â”‚   â”œâ”€â”€ routers/    # API routes
â”‚       â”‚   â”œâ”€â”€ dependencies.py
â”‚       â”‚   â”œâ”€â”€ errors.py
â”‚       â”‚   â””â”€â”€ middleware/
â”‚       â””â”€â”€ schemas/         # Pydantic schemas
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/               # Unit tests
â”‚   â””â”€â”€ integration/        # Integration tests
â”œâ”€â”€ scripts/                # Helper scripts
â”œâ”€â”€ docs/                   # Documentation
â”œâ”€â”€ Dockerfile              # Multi-stage Dockerfile
â”œâ”€â”€ docker-compose.yml      # Production compose
â”œâ”€â”€ docker-compose.dev.yml  # Development compose
â”œâ”€â”€ Makefile               # Dev commands
â””â”€â”€ pyproject.toml         # Project config
```

## Technology Stack

- **Language:** Python 3.12+
- **Package Manager:** UV
- **Web Framework:** FastAPI
- **ML Framework:** PyTorch
- **Data Processing:** Pandas, NumPy
- **Data Validation:** Pydantic, Pandera
- **ML Tracking:** MLflow
- **Monitoring:** Prometheus
- **Logging:** Structlog
- **Testing:** Pytest
- **Code Quality:** Ruff, Pre-commit
- **Containerization:** Docker, Docker Compose

## Configuration

Configuration is managed via environment variables. Copy `.env.example` to `.env`:

```bash
cp .env.example .env
```

Key environment variables:

```bash
# API Settings
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4

# MLflow Settings
MLFLOW_TRACKING_URI=sqlite:///data/mlflow.db
MLFLOW_EXPERIMENT_NAME=stock_prediction_lstm

# Model Settings
MODEL_HIDDEN_SIZE=50
MODEL_NUM_LAYERS=2
MODEL_EPOCHS=100
```

## MLflow Integration

### View Experiments

```bash
# MLflow UI is available at http://localhost:5000

# Or run standalone
uv run mlflow ui
```

### Model Registry

All trained models are automatically registered in MLflow:

```python
# Load model from registry
from src.infrastructure.mlflow.utils import load_model_from_registry

model = load_model_from_registry("stock_predictor_AAPL", "Production")
```

See [MLflow Guide](docs/mlflow_guide.md) for more details.

## Deployment

See [Deployment Guide](docs/deployment_guide.md) for comprehensive deployment instructions including:

- Local deployment
- Docker deployment
- Kubernetes deployment
- Cloud deployments (AWS, GCP, Azure)
- Monitoring and scaling
- Security best practices

## Monitoring

### Prometheus Metrics

Metrics are exposed at `/metrics`:

- `http_requests_total` - Total HTTP requests
- `http_request_duration_seconds` - Request duration
- `predictions_total` - Total predictions
- `training_total` - Total training requests
- `model_load_duration_seconds` - Model loading time

### Health Checks

```bash
curl http://localhost:8000/api/v1/health
```

Response:
```json
{
  "status": "healthy",
  "version": "0.1.0",
  "timestamp": "2024-12-10T14:30:52Z",
  "dependencies": {
    "mlflow": "connected",
    "yfinance": "accessible"
  }
}
```

## Performance

- **Prediction latency:** < 100ms (cached model)
- **Training time:** ~2-5 minutes (1 year data, 100 epochs)
- **Image size:** ~500MB (multi-stage build)
- **Memory usage:** ~512MB - 2GB (depending on model size)

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests and linting
5. Submit a pull request

```bash
# Before committing
make lint
make test
```

## License

MIT License - see [LICENSE](LICENSE) for details.

## Support

- **Documentation:** [docs/](docs/)
- **API Reference:** http://localhost:8000/docs
- **MLflow UI:** http://localhost:5000
- **Issues:** GitHub Issues

## Roadmap

- [ ] Add more model architectures (GRU, Transformer)
- [ ] Implement model versioning and A/B testing
- [ ] Add authentication and rate limiting
- [ ] Integrate with more data sources
- [ ] Add batch prediction endpoint
- [ ] Implement model explanation (SHAP, LIME)
- [ ] Add WebSocket for real-time predictions
- [ ] Create Grafana dashboards

---

**Built with â¤ï¸ using Clean Architecture and MLOps best practices**
