# ğŸš€ Guia de Deploy em ProduÃ§Ã£o

## ğŸ“‹ Ãndice

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [Problema do SQLite](#problema-do-sqlite)
3. [Arquitetura de ProduÃ§Ã£o](#arquitetura-de-produÃ§Ã£o)
4. [Deploy RÃ¡pido](#deploy-rÃ¡pido)
5. [ConfiguraÃ§Ã£o Detalhada](#configuraÃ§Ã£o-detalhada)
6. [SeguranÃ§a](#seguranÃ§a)
7. [Monitoramento](#monitoramento)
8. [Troubleshooting](#troubleshooting)

---

## ğŸ¯ VisÃ£o Geral

Este guia explica como fazer deploy da API de prediÃ§Ã£o de aÃ§Ãµes em **produÃ§Ã£o** usando PostgreSQL em vez de SQLite.

### Por que mudar do SQLite?

**Problema:** SQLite nÃ£o suporta mÃºltiplos processos escrevendo simultaneamente.

**Sintomas:**
- Erros: `Can't locate revision identified by '1bd49d398cd23'`
- Modelos nÃ£o aparecem no Model Registry
- Database locks e timeouts

**SoluÃ§Ã£o:** Use PostgreSQL para concorrÃªncia robusta.

---

## ğŸ—ï¸ Arquitetura de ProduÃ§Ã£o

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Load Balancer / Nginx              â”‚
â”‚           (SSL/TLS Termination)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                        â”‚
             â–¼                        â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  API Service    â”‚      â”‚  MLflow Server   â”‚
   â”‚  (Port 8000)    â”‚â—„â”€â”€â”€â”€â”€â”¤  (Port 5000)     â”‚
   â”‚  4 workers      â”‚      â”‚  Tracking + UI   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                        â”‚
            â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
            â””â”€â”€â”€â”€â–º   PostgreSQL     â”‚â”‚
                 â”‚   (Port 5432)    â”‚â”‚
                 â”‚   - MLflow DB    â”‚â”‚
                 â”‚   - Registry     â”‚â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
                          â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  Artifact Store   â”‚
                 â”‚  (Volume/S3)      â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Vantagens:**
- âœ… Zero conflitos de banco de dados
- âœ… Suporta mÃºltiplos workers
- âœ… MLflow UI separado da API
- âœ… EscalÃ¡vel horizontalmente
- âœ… Backups simplificados

---

## âš¡ Deploy RÃ¡pido

### 1. Criar arquivo de ambiente

Crie `.env.production`:

```bash
# Database
POSTGRES_USER=mlflow
POSTGRES_PASSWORD=seu_password_super_seguro_aqui
POSTGRES_DB=mlflow

# MLflow
MLFLOW_TRACKING_URI=http://mlflow-server:5000
MLFLOW_ALLOWED_HOSTS=*

# API
API_WORKERS=4
LOG_LEVEL=info
```

### 2. Iniciar serviÃ§os

```bash
# Build e start com PostgreSQL
docker-compose -f docker-compose.prod.yml --env-file .env.production up -d

# Verificar status
docker-compose -f docker-compose.prod.yml ps

# Verificar logs
docker-compose -f docker-compose.prod.yml logs -f api
```

### 3. Verificar saÃºde

```bash
# API Health
curl http://localhost:8000/api/v1/health

# MLflow Health
curl http://localhost:5000/health

# Treinar modelo de teste
curl -X POST http://localhost:8000/api/v1/train \
  -H "Content-Type: application/json" \
  -d '{"symbol": "AAPL", "period": "1y", "config": {"epochs": 50}}'

# Verificar modelos registrados
curl http://localhost:8000/api/v1/models
```

---

## âš™ï¸ ConfiguraÃ§Ã£o Detalhada

### VariÃ¡veis de Ambiente CrÃ­ticas

#### Database (PostgreSQL)
```bash
POSTGRES_USER=mlflow              # UsuÃ¡rio do banco
POSTGRES_PASSWORD=***             # Password forte (min 16 chars)
POSTGRES_DB=mlflow                # Nome do database
```

#### MLflow
```bash
MLFLOW_TRACKING_URI=http://mlflow-server:5000
MLFLOW_ALLOWED_HOSTS=api.seudominio.com,mlflow.seudominio.com
MLFLOW_EXPERIMENT_NAME=stock_prediction_lstm
```

#### API
```bash
API_WORKERS=4                     # 2-4 por CPU core
LOG_LEVEL=info                    # debug|info|warning|error
API_HOST=0.0.0.0
API_PORT=8000
```

### Recursos Recomendados

| Componente | CPU | RAM | Storage |
|------------|-----|-----|---------|
| API | 2 cores | 2GB | 10GB |
| MLflow Server | 1 core | 1GB | 5GB |
| PostgreSQL | 2 cores | 2GB | 20GB+ |

---

## ğŸ”’ SeguranÃ§a

### 1. Segredos e Senhas

**NUNCA** commite senhas no Git! Use:

```bash
# Gerar senha segura
openssl rand -base64 32

# Usar secrets manager (AWS, GCP, Azure)
export POSTGRES_PASSWORD=$(aws secretsmanager get-secret-value --secret-id prod/mlflow/db-password --query SecretString --output text)
```

### 2. Network Security

```yaml
# docker-compose.prod.yml
services:
  postgres:
    # NÃƒO expor porta externamente
    # ports:  # â† Comentado!
    #   - "5432:5432"
    networks:
      - stock-prediction-network  # Apenas internal
```

### 3. SSL/TLS

Use Nginx ou Traefik como reverse proxy:

```nginx
server {
    listen 443 ssl http2;
    server_name api.seudominio.com;

    ssl_certificate /etc/ssl/certs/api.crt;
    ssl_certificate_key /etc/ssl/private/api.key;

    location / {
        proxy_pass http://localhost:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

### 4. Rate Limiting

Adicione no Nginx:

```nginx
limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;

location /api/v1/train {
    limit_req zone=api_limit burst=5 nodelay;
    proxy_pass http://localhost:8000;
}
```

---

## ğŸ“Š Monitoramento

### 1. Health Checks

```bash
# Script de monitoramento
#!/bin/bash
HEALTH_URL="http://localhost:8000/api/v1/health"

response=$(curl -s -o /dev/null -w "%{http_code}" $HEALTH_URL)

if [ $response -eq 200 ]; then
    echo "âœ… API is healthy"
else
    echo "âŒ API is unhealthy (HTTP $response)"
    # Alertar via PagerDuty, Slack, etc
fi
```

### 2. Prometheus Metrics

```yaml
# docker-compose.prod.yml
services:
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
```

```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'stock-api'
    static_configs:
      - targets: ['api:8000']
    metrics_path: '/metrics'
```

### 3. Grafana Dashboard

```bash
docker-compose -f docker-compose.prod.yml -f docker-compose.monitoring.yml up -d
```

Acesse: http://localhost:3000

**MÃ©tricas importantes:**
- Request rate (req/s)
- Response time (p50, p95, p99)
- Error rate (%)
- Training duration
- Model registry size

---

## ğŸ³ Deploy em Cloud

### AWS (ECS/Fargate)

```bash
# 1. Build e push para ECR
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin YOUR_ACCOUNT.dkr.ecr.us-east-1.amazonaws.com
docker build -t stock-prediction-api .
docker tag stock-prediction-api:latest YOUR_ACCOUNT.dkr.ecr.us-east-1.amazonaws.com/stock-prediction-api:latest
docker push YOUR_ACCOUNT.dkr.ecr.us-east-1.amazonaws.com/stock-prediction-api:latest

# 2. RDS PostgreSQL
# Criar via console ou Terraform

# 3. Deploy no ECS
aws ecs create-cluster --cluster-name stock-prediction-cluster
```

### GCP (Cloud Run)

```bash
# 1. Build e push para GCR
gcloud builds submit --tag gcr.io/YOUR_PROJECT/stock-prediction-api

# 2. Cloud SQL PostgreSQL
gcloud sql instances create mlflow-db --tier=db-f1-micro --region=us-central1

# 3. Deploy no Cloud Run
gcloud run deploy stock-prediction-api \
  --image gcr.io/YOUR_PROJECT/stock-prediction-api \
  --platform managed \
  --region us-central1 \
  --add-cloudsql-instances YOUR_PROJECT:us-central1:mlflow-db
```

### Kubernetes (K8s)

```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: stock-prediction-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: stock-prediction-api
  template:
    metadata:
      labels:
        app: stock-prediction-api
    spec:
      containers:
      - name: api
        image: your-registry/stock-prediction-api:latest
        ports:
        - containerPort: 8000
        env:
        - name: MLFLOW_TRACKING_URI
          value: "postgresql://mlflow:password@postgres:5432/mlflow"
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
```

---

## ğŸ”§ Troubleshooting

### Problema: "Can't locate revision"

**Causa:** Banco de dados corrompido ou migraÃ§Ãµes conflitantes.

**SoluÃ§Ã£o:**
```bash
# Parar tudo
docker-compose -f docker-compose.prod.yml down -v

# Limpar volumes
docker volume rm mlops_lstm_stock_prediction_postgres-data

# Reiniciar
docker-compose -f docker-compose.prod.yml up -d
```

### Problema: API lenta

**DiagnÃ³stico:**
```bash
# Verificar uso de recursos
docker stats

# Logs detalhados
docker-compose -f docker-compose.prod.yml logs -f api | grep "request_duration"
```

**SoluÃ§Ãµes:**
- Aumentar `API_WORKERS`
- Adicionar cache Redis
- Usar GPU para treinamento
- Escalar horizontalmente

### Problema: Out of Memory

**SoluÃ§Ã£o:**
```yaml
# docker-compose.prod.yml
services:
  api:
    deploy:
      resources:
        limits:
          memory: 4G
```

---

## ğŸ“š ReferÃªncias

- [MLflow Deployment](https://mlflow.org/docs/latest/deployment.html)
- [PostgreSQL Tuning](https://www.postgresql.org/docs/current/performance-tips.html)
- [Docker Best Practices](https://docs.docker.com/develop/dev-best-practices/)
- [FastAPI Deployment](https://fastapi.tiangolo.com/deployment/)

---

## ğŸ“ Suporte

Para issues especÃ­ficos do projeto:
- GitHub Issues: [link-do-repo]
- Email: [seu-email]

**Ãšltima atualizaÃ§Ã£o:** Dezembro 2025
